from utils.dataset_loader import BrainTumorDataset
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from torch.utils.data import DataLoader, Subset
import torch

# ×”× ×ª×™×‘ ×œ×“××˜×” (××™×¤×” ×”-Training ×™×•×©×‘)
data_path = "/Users/galshemesh/Desktop/gal shemesh payton/PythonProject1/archive (1)/Training"
import os

# × ×‘×“×•×§ ××” ×™×© ×‘×ª×™×§×™×™×” ×”×¨××©×™×ª
data_path = "/Users/galshemesh/Desktop/gal shemesh payton/PythonProject1/archive (1)/Training"

print("×ª×™×§×™×•×ª ×©× ××¦××•×ª ×‘×ª×•×š Training:")
print(os.listdir(data_path))

# ×˜×•×¢× ×™× ××ª ×”×“××˜×”
dataset = BrainTumorDataset(root_dir=data_path)

# ×‘×•×“×§×™× ×›××” ×ª××•× ×•×ª ×™×©
print(f"Number of images: {len(dataset)}")

# ××—×œ×§×™× ××ª ×”×“××˜×” ×œ-80% Train ×•-20% Validation
indices = list(range(len(dataset)))
train_indices, val_indices = train_test_split(indices, test_size=0.2, random_state=42)

# ×™×•×¦×¨×™× ×ª×ª×™-×“××˜×”
train_dataset = Subset(dataset, train_indices)
val_dataset = Subset(dataset, val_indices)

# ×™×•×¦×¨×™× DataLoaders
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)

# ×”×“×¤×¡×” - ×›××” ×™×© ×‘×›×œ ×—×œ×§
print(f"Train samples: {len(train_dataset)}")
print(f"Validation samples: {len(val_dataset)}")

# ××¦×™×’×™× ×“×•×’×× ××—×ª ×× ×™×© ×“××˜×”

import torch.nn as nn
import torch.nn.functional as F

# × ×’×“×™×¨ ×¨×©×ª CNN ×¤×©×•×˜×”
class BrainTumorCNN(nn.Module):
    def __init__(self):
        super(BrainTumorCNN, self).__init__()
        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)
        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)
        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)
        self.fc1 = nn.Linear(32 * 32 * 32, 128)
        # ×”×ª×××” ×œ×¤×™ ×’×•×“×œ ×ª××•× ×”
        self.fc2 = nn.Linear(128, 4)  # ×™×© 4 ×§×˜×’×•×¨×™×•×ª: glioma, meningioma, pituitary, no tumor

    def forward(self, x):
        x = self.pool(F.relu(self.conv1(x)))
        x = self.pool(F.relu(self.conv2(x)))
        x = x.view(x.size(0), -1)  # ğŸ› ï¸ ×©×™××•×© ×‘×’×•×“×œ ××•×˜×•××˜×™
        x = F.relu(self.fc1(x))
        x = self.fc2(x)
        return x


# ×”×’×“×¨×ª ×”××•×“×œ
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = BrainTumorCNN().to(device)

# ×¤×•× ×§×¦×™×™×ª ××™×‘×•×“
criterion = nn.CrossEntropyLoss()

# ××•×¤×˜×™××™×™×–×¨
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
# ×œ×•×œ××ª ××™××•×Ÿ
num_epochs = 5  # × ×ª×—×™×œ ×‘×§×˜×Ÿ - 5 ××¤×•×§×™×
for epoch in range(num_epochs):
    model.train()  # ××¦×‘ ××™××•×Ÿ
    running_loss = 0.0
    correct = 0
    total = 0

    for images, labels in train_loader:
        # ××¢×‘×™×¨×™× ×œ-Device (GPU ×× ×™×©, ××—×¨×ª CPU)
        images = images.permute(0, 3, 1, 2)  # ×œ×”×¤×•×š ×-HWC ×œ-CHW
        images = images.float() / 255.0  # × ×¨××•×œ ×œ-0-1
        images = images.to(device)
        labels = labels.to(device)

        # ××¤×¡ ×’×¨×“×™×× ×˜×™×
        optimizer.zero_grad()

        # ×ª×—×–×™×ª
        outputs = model(images)

        # ×—×™×©×•×‘ ×”×¤×¡×“
        loss = criterion(outputs, labels)

        # ×—×™×©×•×‘ ×’×¨×“×™×× ×˜×™× ×•×¢×“×›×•×Ÿ ××©×§×œ×™×
        loss.backward()
        optimizer.step()

        running_loss += loss.item()

        # ×—×™×©×•×‘ ×“×™×•×§
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

    epoch_loss = running_loss / len(train_loader)
    epoch_acc = 100 * correct / total

    print(f"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.2f}%")

print("Finished Training âœ…")
# ======================================
# ×”×¢×¨×›×ª ×”××•×“×œ ×¢×œ ×”-Validation Set
# ======================================
model.eval()  # ××¦×‘ ×”×¢×¨×›×”, ×œ× ××™××•×Ÿ
val_loss = 0.0
correct = 0
total = 0

with torch.no_grad():  # ××™×Ÿ ×¦×•×¨×š ×‘×’×¨×“×™×× ×˜×™× ×‘×‘×“×™×§×”
    for images, labels in val_loader:
        images = images.permute(0, 3, 1, 2)
        images = images.float() / 255.0
        images = images.to(device)
        labels = labels.to(device)

        outputs = model(images)
        loss = criterion(outputs, labels)

        val_loss += loss.item()

        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

avg_val_loss = val_loss / len(val_loader)
val_accuracy = 100 * correct / total

print(f"\nValidation Loss: {avg_val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%")


    # ======================================
    # ×©××™×¨×ª ×”××•×“×œ ×”×××•××Ÿ
    # ======================================
model_save_path = "brain_tumor_model.pth"
torch.save(model.state_dict(), model_save_path)
print(f"\nâœ… Model saved to {model_save_path}")
